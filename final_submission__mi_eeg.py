# -*- coding: utf-8 -*-
"""Final Submission_ MI-EEG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cn-gDEhx6XVzAbpghKG1foI9dsts0CIk

# Pre-Requisites
"""

pip install PyQt5

pip install mne

pip install --upgrade typing-extensions

pip install --user matplotlib

#pip install --upgrade matplotlib

pip install ssqueezepy

pip install timm

pip install pytorch-lightning

#pip install ipdb

"""# Importing Libraries and Data"""

import mne
import matplotlib
import matplotlib.pyplot as plt
import PyQt5
import pandas as pd
import numpy as np
import seaborn as sns
import os
import glob
from ssqueezepy import cwt
from ssqueezepy.visuals import plot, imshow

from tensorflow.keras.layers import Conv1D,BatchNormalization,LeakyReLU,MaxPool1D, GlobalAveragePooling1D,Dense,Dropout,AveragePooling1D
from tensorflow.keras.models import Sequential
from tensorflow.keras.backend import clear_session

from tensorflow.keras.layers import Input, Dense, concatenate, Flatten, GRU, Conv1D, Conv2D, LSTM, Bidirectional
from tensorflow.keras.models import Model
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from keras import regularizers
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GroupKFold,LeaveOneGroupOut
from tensorflow.keras.regularizers import l2

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

import tensorflow as tf

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!cp /content/drive/MyDrive/BCICIV_2a_gdf.zip /content

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !unzip /content/BCICIV_2a_gdf.zip -d data

#rm -rf '/content/data'



"""# BCI Competition IV dataset 2a

##Data Visualization and Preporcessing for particular subject

### Data Visualization :-
"""

# For analysis of data, we are considering single subject(A01) at a time
directory_path = '/content/data/'
eeg_data = mne.io.read_raw_gdf(directory_path+"A01T.gdf", eog = ['EOG-left', 'EOG-central', 'EOG-right'], preload = True)

# checking the description of the EEG data
eeg_data.info

"""##### We can observe that, 22 channels are present out of which 3 are EOG channels and the data is sampled at a rate of 250 Hz"""

# checking the channel names of the EEG data
print("Present channel names: \n",eeg_data.info['ch_names'])

"""##### Most of the channel names are not properly mentioned. Therefore, we need to rename the channel names so that they can be recognized by the Standard 10-20 system"""

## Creating Channel maps to replace channel names with 10_20 montage approved channel names
## Comparing BC_IV-2A dataset with diagrams of
## https://www.researchgate.net/figure/The-channel-configuration-of-the-International-10-20-system-62-EEG-and-4-EMG-recording_fig1_330745291

channel_maps = {
    'EEG-Fz': 'Fz','EEG-0': 'FC3','EEG-1': 'FC1','EEG-2': 'FCz','EEG-3': 'FC2',
    'EEG-4': 'FC4','EEG-5': 'C5','EEG-C3': 'C3','EEG-6': 'C1','EEG-Cz': 'Cz',
    'EEG-7': 'C2','EEG-C4': 'C4','EEG-8': 'C6','EEG-9': 'CP3','EEG-10': 'CP1',
    'EEG-11': 'CPz','EEG-12': 'CP2','EEG-13': 'CP4','EEG-14': 'P1','EEG-Pz': 'Pz',
    'EEG-15': 'P2','EEG-16': 'POz',
}

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # Renaming the channels with the International 10-20 system
# eeg_data.rename_channels(channel_maps)

print("Modified Channel names(10-20 system): \n", eeg_data.info['ch_names'])

# checking the presence of bad channels
eeg_data.info['bads']

# Dropping EOG channels as we are not interested in EOG channels
eeg_data.drop_channels(['EOG-left','EOG-central','EOG-right'])

"""##### No presence of bad channels"""

#%%capture
# Setting EEG reference
#eeg_data.set_eeg_reference()

# Selection of Standard_10-20 montage system
montage = mne.channels.make_standard_montage('standard_1020')

# plotting of International 10-20 EEG-system for reference
montage.plot()

# Referencing and settings montages for checking the layout of EEG electrode positions of the current data
eeg_data.set_montage(montage)
eeg_data.plot_sensors(show_names=True)

eeg_data.info

# Visualizing the spectral density of the EEG signals

# plot for average power spectral density of all channels
PSD = eeg_data.compute_psd(fmax= 120)
PSD.plot(average=True)

# plot all channel
PSD.plot()

plt.plot()

# Visualizing topographical data on a 2D scalp projection.
# projecting the brain regions activity across different frequency bands

PSD.plot_topomap()

"""##### Checking sample EEG-signals for selected channels within limited duration"""

import plotly.express as px
import plotly.graph_objects as go

sampling_freq = eeg_data.info['sfreq']
start_time  = 50
end_time = 52
sample_channels = ['C3', 'C4', 'Cz']
start_sample = int(start_time * sampling_freq)
end_sample = int(end_time * sampling_freq)
sample_data = eeg_data[sample_channels,start_sample: end_sample]

X = sample_data[1]
Y = sample_data[0].T
np.shape(X)

fig = go.Figure()

# Loop through each dataset in Y and plot it against X
for i in range(Y.shape[1]):
    fig.add_trace(go.Scatter(x=X, y=Y[:, i], mode='lines',name = sample_channels[i]))

fig.show()

# Creating events from the annotations

eeg_events = mne.events_from_annotations(eeg_data)
eeg_events

# For detailed understanding we are creating a dictionary for event notations
# the description of every event types:
# 'Rejected trial':1023,
# 'Eye movements':1072,
# 'Idling EEG (eyes open)':276,
# 'Idling EEG (eyes closed)':277,
# 'Start of a new run':32766,
# 'Start of a trial':768,
# *'Cue onset left (class 1)':769,
# *'Cue onset right (class 2)':770,
# *'Cue onset foot (class 3)':771,
# *'Cue onset tongue (class 4)':772
event_notations = {'Eyes Open':3, 'Eyes Closed':4,
                   'Start of a trial':6, 'Left Limb':7,
                   'Right Limb0':8, 'Foot':9,
                   'Tongue':10, 'Unknown':1,
                   'Eye Movement':2, 'Start of a new run':5,
                  }

# Plotting Events of the experiment

Figure = mne.viz.plot_events(eeg_events[0], event_id=event_notations, sfreq = eeg_data.info['sfreq'],
                            first_samp=eeg_data.first_samp)

"""### Data Preprocessing"""

## sliding window mechanism for data augmentation

def cropper (signals, labels, window, step):


    time   = signals.shape[2]             # number of time points
    begs   = list(range(0, time, step))   # begining indices of sliding windows
    crops  = list()                       # list contaiing croppend signals
    annots = list()                       # labels of cropped signals

    for i in range(signals.shape[0]):
        for j in begs:
            if j + window <= time:
                crops .append(signals[i:i+1, :, j:j+window])
                annots.append(labels[i])

    crops  = np.concatenate(crops, axis=0)
    annots = np.array(annots)

    return crops, annots

# 1. Apply band-pass filter of frequency range of interests.
# 2. Before resampling, apply a low-pass filter to prevent aliasing.

# filtering raw EEG data (4Hz,40Hz). Considering theta, mu/alpha, beta bands
filtered_eeg_data = eeg_data.copy()
filtered_eeg_data.filter(l_freq=7, h_freq=40)

# resample the filtered data to 250Hz
filtered_eeg_data.resample(sfreq=250)
print(filtered_eeg_data.info)

# Plotting raw and filtered data
eeg_data.plot(title='no filter raw data')
filtered_eeg_data.plot(title='filtered data')

print(filtered_eeg_data)

# rename annotation description to reject when segmenting epochs (origin dataset description '1023')
filtered_eeg_data.annotations.rename({'1023': 'bad_1023'})

# Creating events from the annotations
events_mapping = {'276':276, '277':277, '768':768, '769':769, '770':770, '771':771, '772':772, '783':783, 'bad_1023':1023, '1072': 1072, '32766':32766}
eeg_events2 = mne.events_from_annotations(filtered_eeg_data, event_id=events_mapping)
eeg_events2

# segment into epochs by events(-0.2s 0.8s)
eeg_epochs = mne.Epochs(filtered_eeg_data, eeg_events2[0], tmin=-0.2, tmax=0.8, event_repeated='merge',preload=True, event_id={'left':769, 'right': 770, 'foot': 771, 'tongue':772})
print("epochs information: ", eeg_epochs)
print("epochs dropped for: ", set(eeg_epochs.drop_log))

evoked_left = eeg_epochs['left'].average()
evoked_right = eeg_epochs['right'].average()
evoked_foot = eeg_epochs['foot'].average()
evoked_tongue = eeg_epochs['tongue'].average()

evoked_dict = {'left':evoked_left,'right':evoked_right,'foot':evoked_foot,'tongue':evoked_tongue}

# visualize the average epochs fig for 4 classes
eeg_epochs['left'].plot_image(title='left hand', combine='mean')
eeg_epochs['right'].plot_image(title='right hand', combine='mean')
eeg_epochs['foot'].plot_image(title='both feet', combine='mean')
eeg_epochs['tongue'].plot_image(title='tongue', combine='mean')

# plot the evoked fig
mne.viz.plot_compare_evokeds(evoked_dict)

eeg_epochs.get_data().shape

# converting epochs to Dataframe

data = eeg_epochs.to_data_frame()
data.head()

labels = eeg_epochs.events[:,-1]

x_train, y_train = cropper(eeg_epochs.get_data(), labels, window=100, step=100)
print(x_train.shape, y_train.shape)

"""## Dataset creation including all subjects"""

directory_path = '/content/data/'
sampling_frequency = 250
lower_cutoff = 4
higher_cutoff = 40
start_time = -0.2
end_time = 1.5

def preprocess(path, subject_id):
  # reading subject data
  eeg_data = mne.io.read_raw_gdf(directory_path+f"A0{subject_id}T.gdf", eog = ['EOG-left', 'EOG-central', 'EOG-right'], preload = True)

  # creating maps for channel names
  channel_maps = {
    'EEG-Fz': 'Fz','EEG-0': 'FC3','EEG-1': 'FC1','EEG-2': 'FCz','EEG-3': 'FC2',
    'EEG-4': 'FC4','EEG-5': 'C5','EEG-C3': 'C3','EEG-6': 'C1','EEG-Cz': 'Cz',
    'EEG-7': 'C2','EEG-C4': 'C4','EEG-8': 'C6','EEG-9': 'CP3','EEG-10': 'CP1',
    'EEG-11': 'CPz','EEG-12': 'CP2','EEG-13': 'CP4','EEG-14': 'P1','EEG-Pz': 'Pz',
    'EEG-15': 'P2','EEG-16': 'POz',
  }

  # renaming channels
  eeg_data.rename_channels(channel_maps)

  # dropping EOG channels
  eeg_data.drop_channels(['EOG-left','EOG-central','EOG-right'])

  # setting standard montage
  montage = mne.channels.make_standard_montage('standard_1020')
  eeg_data.set_montage(montage)

  # setting 'average' reference
  #eeg_data1.set_eeg_reference()

  # applying bandpass filter
  filtered_eeg_data = eeg_data.copy()
  filtered_eeg_data.filter(l_freq=lower_cutoff, h_freq=higher_cutoff)

  # resampling data
  filtered_eeg_data.resample(sfreq=sampling_frequency)

  # removing discarded trials
  filtered_eeg_data.annotations.rename({'1023': 'bad_1023'})

  events_mapping = {'276':276, '277':277, '768':768, '769':769, '770':770, '771':771, '772':772, '783':783, 'bad_1023':1023, '1072': 1072, '32766':32766}

  # creating events from annotations
  eeg_events = mne.events_from_annotations(filtered_eeg_data, event_id=events_mapping)
  #print(eeg_events)

  # creating epochs/trials
  eeg_epochs = mne.Epochs(filtered_eeg_data, eeg_events[0], tmin=start_time, tmax=end_time, event_repeated='merge',preload=True, event_id={'left':769, 'right': 770, 'foot': 771, 'tongue':772})
  #print("epochs information: ", eeg_epochs)
  #print("epochs dropped for: ", set(eeg_epochs.drop_log))


  # creating Dataframe
  #data = eeg_epochs.to_data_frame()

  # creating features in form of matrices
  ## Creating Labels for the dataset
  labels = eeg_epochs.events[:,-1]

  ## Creating labels for the dataset
  predictors = eeg_epochs.get_data()


  predictor, label = cropper(predictors, labels, window=100, step=100)
  return predictor, label

#%%capture
data_list, label_list = [],[]
for subject in range(1,10):
  #print("===>", subject)
  predictors, labels = preprocess(directory_path, subject)
  print("++++++++++++++",predictors.shape, labels.shape)

  data_list.append(predictors)
  label_list.append(labels)
  #print("--->", label_list[:10])

# creating list of groups

groups_list=[[i]*len(j) for i, j in enumerate(data_list)]

# merging all participant's data

data_array=np.vstack(data_list)
label_array=np.hstack(label_list)
group_array=np.hstack(groups_list)
print(data_array.shape,label_array.shape,group_array.shape)

# converting the labels

label_array[label_array == 769] = 0
label_array[label_array == 770] = 1
label_array[label_array == 771] = 2
label_array[label_array == 772] = 3

# changing axis to make it tensorflow compatible

data_array=np.moveaxis(data_array,1,2)

print(data_array.shape,label_array.shape,group_array.shape)

unique_elements, counts = np.unique(group_array, return_counts = True)

print("Unique elements:", unique_elements)
print("Counts:", counts)

"""#### GroupSplitting:"""

## 9312 - 948 where 948 is the size of the 9th participant

train_data_array,train_label_array,train_group_array =  data_array[:8364],label_array[:8364],group_array[:8364]
test_data_array,test_label_array,test_group_array =  data_array[8364:],label_array[8364:],group_array[8364:]

train_group_array

"""#### Data Normalization"""

accuracy=[]

# one hot encoding the labels
train_label_array_oneHot = tf.keras.utils.to_categorical(train_label_array, num_classes=4)
test_label_array_oneHot = tf.keras.utils.to_categorical(test_label_array, num_classes=4)

from sklearn.preprocessing import StandardScaler
#scaling the data using standard scalar
scaler=StandardScaler()
training_features = scaler.fit_transform(train_data_array.reshape(-1, train_data_array.shape[-1])).reshape(train_data_array.shape)
testing_features = scaler.transform(test_data_array.reshape(-1, test_data_array.shape[-1])).reshape(test_data_array.shape)

training_features.shape

"""# Deep Learning Models

### DeepConvCNN model
"""

## Creating DeepConvNet

def cnnmodel():
    clear_session()
    model=Sequential()
    model.add(Conv1D(filters=5,kernel_size=3,strides=1,input_shape=(100,22)))
    model.add(BatchNormalization())
    model.add(LeakyReLU())
    model.add(MaxPool1D(pool_size=2,strides=2))
    model.add(Conv1D(filters=5,kernel_size=3,strides=1))
    model.add(LeakyReLU())
    model.add(MaxPool1D(pool_size=2,strides=2))
    model.add(Dropout(0.10))
    model.add(Conv1D(filters=5,kernel_size=3,strides=1))
    model.add(LeakyReLU())
    model.add(AveragePooling1D(pool_size=2,strides=2))
    model.add(Dropout(0.10))
    model.add(Conv1D(filters=5,kernel_size=3,strides=1))
    model.add(LeakyReLU())
    model.add(AveragePooling1D(pool_size=2,strides=2))
    model.add(Conv1D(filters=5,kernel_size=3,strides=1))
    model.add(LeakyReLU())
    model.add(GlobalAveragePooling1D())
    model.add(Dense(4,activation='softmax'))

    model.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])
    return model

model=cnnmodel()
model.summary()

# Training the model

model_CNN=cnnmodel()
gkf=GroupKFold()
for train_index, val_index in gkf.split(training_features, train_label_array_oneHot, groups=train_group_array):
    #print(train_index, val_index)
    train_features,train_labels=training_features[train_index],train_label_array_oneHot[train_index]
    val_features,val_labels=training_features[val_index],train_label_array_oneHot[val_index]
    model.fit(train_features,train_labels,epochs=30,batch_size=16,validation_data=(val_features,val_labels))
    accuracy.append(model.evaluate(val_features,val_labels)[1])

predictionsCNN = model_CNN.predict(testing_features)

predCNN = np.argmax(predictionsCNN, axis=1)

## checking accuracy

accuracy = np.mean(predCNN == test_label_array)

# creating confusion matrix and classification report

print(confusion_matrix(test_label_array, predCNN))
print(classification_report(test_label_array, predCNN ))

plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix for DeepConvNet')
plt.show()

"""### Inception ChronoNet"""

## Creating ChronoNet

def convolution_stage(input):
  convBlock1 = Conv1D(32, kernel_size = 2,strides = 2, padding = 'same',activation = 'relu')(input)
  convBlock2 = Conv1D(32, kernel_size = 4,strides = 2, padding = 'causal', activation = 'relu')(input)
  convBlock3 = Conv1D(32, kernel_size = 8,strides = 2, padding = 'causal', activation = 'relu')(input)
  concatenated_result = concatenate([convBlock1, convBlock2, convBlock3], axis = 2)
  dropout_result = Dropout(0.2)(concatenated_result)
  return dropout_result
def ChronoNet(input):
  convolutionStage1 = convolution_stage(input)
  convolutionStage2 = convolution_stage(convolutionStage1)
  convolutionStage3 = convolution_stage(convolutionStage2)
  recurrent_regularizer = regularizers.l1(0.01)
  kernel_regularizer= regularizers.l2(0.01)
  bias_regularizer = regularizers.l1(0.01)
  gruStage1 = GRU(32,activation='tanh',return_sequences=True,
              recurrent_regularizer=recurrent_regularizer,
              kernel_regularizer=kernel_regularizer,
              bias_regularizer=bias_regularizer
                  )(convolutionStage3)
  gruStage2 = GRU(32, activation = 'tanh', return_sequences= True,
              recurrent_regularizer=recurrent_regularizer,
              kernel_regularizer=kernel_regularizer,
              bias_regularizer=bias_regularizer
                  )(gruStage1)
  concatGRUStage1 = concatenate([gruStage1, gruStage2], axis = 2)
  gruStage3 = GRU(32, activation = 'tanh', return_sequences=True,
              recurrent_regularizer=recurrent_regularizer,
              kernel_regularizer=kernel_regularizer,
              bias_regularizer=bias_regularizer
                  )(concatGRUStage1)
  concatGRUStage2 = concatenate([gruStage3, gruStage1, gruStage2])
  gruStage4 = GRU(32, activation ='tanh')(concatGRUStage2)
  return gruStage4

input = Input(shape=(100,22))
ChronoNet_Output = ChronoNet(input)
print(ChronoNet_Output.shape)
output = Dense(4, activation='softmax')(ChronoNet_Output)
model_ChronoNet = Model(inputs=input, outputs=output)

model_ChronoNet.compile(optimizer="adam", loss='categorical_crossentropy', metrics=["accuracy"],
              #loss_weights=[recurrent_loss, kernel_loss, bias_loss]
              )

dot_img_file = '/tmp/model_1.png'
tf.keras.utils.plot_model(model_ChronoNet, to_file=dot_img_file, show_shapes=True)

accuracy=[]
gkf=GroupKFold()
for train_index, val_index in gkf.split(training_features, train_label_array_oneHot, groups=train_group_array):
    train_features,train_labels=training_features[train_index],train_label_array_oneHot[train_index]
    val_features,val_labels=training_features[val_index],train_label_array_oneHot[val_index]

    model_ChronoNet.fit(train_features,train_labels,epochs=20,batch_size=64,validation_data=(val_features,val_labels))
    accuracy.append(model_ChronoNet.evaluate(val_features,val_labels)[1])

predictionsChronoNet = model_ChronoNet.predict(testing_features)

predChronoNet = np.argmax(predictionsChronoNet, axis=1)

## checking accuracy

accuracy = np.mean(predChronoNet == test_label_array)

# creating confusion matrix and classification report

print(confusion_matrix(test_label_array, predChronoNet))
print(classification_report(test_label_array, predChronoNet ))

plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix for ChronoNet')
plt.show()



"""### EEGNET"""

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, AveragePooling2D, SeparableConv2D
from tensorflow.keras.layers import Activation, Flatten, Dense
from tensorflow.keras.constraints import max_norm
from tensorflow.keras.layers import BatchNormalization

def EEGNet(nb_classes, Chans=22, Samples=100, dropout_rate=0.15, kern_length=64, F1=8, D=2, F2=32, norm_rate=0.25, dropout_type='Dropout'):
    input1 = tf.keras.layers.Input(shape=(Chans, Samples, 1))
    block1 = Conv2D(F1, (1, kern_length), padding='same', input_shape=(Chans, Samples, 1), use_bias=False)(input1)
    block1 = BatchNormalization()(block1)
    block1 = DepthwiseConv2D((Chans, 1), use_bias=False, depth_multiplier=D, depthwise_constraint=max_norm(norm_rate))(block1)
    block1 = BatchNormalization()(block1)
    block1 = Activation('elu')(block1)
    block1 = AveragePooling2D((1, 4))(block1)
    block1 = tf.keras.layers.Dropout(dropout_rate)(block1)

    block2 = SeparableConv2D(F2, (1, 16), use_bias=False, padding='same')(block1)
    block1 = BatchNormalization()(block2)
    block2 = Activation('elu')(block2)
    block2 = AveragePooling2D((1, 8))(block2)
    block2 = tf.keras.layers.Dropout(dropout_rate)(block2)

    flatten = Flatten(name='flatten')(block2)
    dense = Dense(nb_classes, name='dense', kernel_constraint=max_norm(norm_rate), activation='softmax')(flatten)

    model = tf.keras.Model(inputs=input1, outputs=dense)

    return model

# Initialize EEGNet
model_EEGNET = EEGNet(nb_classes=4)
model_EEGNET.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

dot_img_file = '/tmp/model_2.png'
tf.keras.utils.plot_model(model_EEGNET, to_file=dot_img_file, show_shapes=True)

# 4D scaling to fit the data into the EEGNet architecture

scaler=StandardScaler()

training_features = scaler.fit_transform(train_data_array.reshape(-1, 22)).reshape(train_data_array.shape[0], train_data_array.shape[2], train_data_array.shape[1], 1)
testing_features = scaler.transform(test_data_array.reshape(-1, 22)).reshape(test_data_array.shape[0],test_data_array.shape[2], test_data_array.shape[1],  1)

training_features.shape

accuracy=[]
gkf=GroupKFold()
for train_index, val_index in gkf.split(training_features, train_label_array_oneHot, groups=train_group_array):
    train_features,train_labels=training_features[train_index],train_label_array_oneHot[train_index]
    val_features,val_labels=training_features[val_index],train_label_array_oneHot[val_index]

    model_EEGNET.fit(train_features,train_labels,epochs=20,batch_size=64,validation_data=(val_features,val_labels))
    accuracy.append(model_EEGNET.evaluate(val_features,val_labels)[1])

predictionsEEGNet = model_EEGNET.predict(testing_features)

predEEGNet = np.argmax(predictionsEEGNet, axis=1)

## checking accuracy

accuracy = np.mean(predEEGNet == test_label_array)

# creating confusion matrix and classification report

print(confusion_matrix(test_label_array, predEEGNet))
print(classification_report(test_label_array, predEEGNet ))

plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix for EEGNET')
plt.show()